Markdown

# üå∏ Classification de Fleurs Iris avec R√©seau Neuronal Dense (DNN)

Ce d√©p√¥t contient un script Python simple (`model.py`) qui impl√©mente et entra√Æne un **R√©seau Neuronal Dense (DNN)** utilisant **TensorFlow/Keras** pour la classification des c√©l√®bres fleurs du jeu de donn√©es **Iris** de Scikit-learn.

## üéØ Objectif du Projet

L'objectif est de pr√©dire l'esp√®ce d'une fleur Iris (Setosa, Versicolor, ou Virginica) en se basant sur quatre caract√©ristiques morphologiques (longueur/largeur des s√©pales et des p√©tales).

---

## ‚öôÔ∏è Configuration et D√©pendances

Ce projet n√©cessite les biblioth√®ques Python suivantes : `tensorflow`, `scikit-learn`, `pandas`, et `numpy`.

### Installation

Pour installer les d√©pendances n√©cessaires, utilisez `pip` dans votre environnement virtuel :

```bash
pip install tensorflow scikit-learn pandas numpy
üöÄ Guide d'Ex√©cution
Cloner le d√©p√¥t :

Bash

git clone [https://github.com/chniang/check_RNA.git](https://github.com/chniang/check_RNA.git)
cd CHECK_RNA
Activer l'environnement virtuel (tf_venv) :
Assurez-vous que votre environnement virtuel est actif pour ex√©cuter le script avec les bonnes d√©pendances.

Bash

# Sous PowerShell (Windows)
.\tf_venv\Scripts\Activate.ps1
# Sous MINGW64 / Linux
source tf_venv/bin/activate
Lancer le script d'entra√Ænement :

Bash

python model.py
R√©sultat de l'√âvaluation
Le script effectue l'entra√Ænement sur 100 √©poques. Le r√©sultat final sur l'ensemble de test (20% des donn√©es) d√©montre l'efficacit√© du mod√®le :

--- √âvaluation du Mod√®le ---
Perte(loss) sur l'ensemble de test:0.0331
Precision(accuracy) sur l'ensemble de test:100.00%
üß† D√©tails du Mod√®le
Pr√©paration des Donn√©es
Encodage One-Hot : Les √©tiquettes de classe (0, 1, 2) sont converties en format One-Hot ([1, 0, 0], etc.) en utilisant to_categorical.

Division : Les donn√©es sont divis√©es en 80% (entra√Ænement) et 20% (test) via train_test_split.

Normalisation : Toutes les caract√©ristiques d'entr√©e sont normalis√©es √† l'aide de StandardScaler pour optimiser la convergence du r√©seau.

Architecture
Le mod√®le utilise une architecture s√©quentielle simple :

Couche	Type	Neurones	Activation	R√¥le
Input	Dense	10	ReLU	Couche d'entr√©e (4 features)
Cach√©e	Dense	8	ReLU	Couche interm√©diaire
Output	Dense	3	Softmax	Couche de sortie (3 classes)

Exporter vers Sheets
Compilation du Mod√®le :

Optimiseur : adam

Fonction de Perte : categorical_crossentropy

M√©triques : accuracy
